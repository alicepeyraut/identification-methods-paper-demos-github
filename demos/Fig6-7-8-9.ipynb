{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig-6-7-8-9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolfin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from generate_images import generate_images_and_meshes_from_RivlinCube ### this file is available in the repository, and can be accessed to see details in the code\n",
    "\n",
    "import dolfin_estim as destim\n",
    "import dolfin_warp as dwarp\n",
    "\n",
    "### disable deprecation warning to avoid heavy output\n",
    "import warnings\n",
    "from ffc.quadrature.deprecation import QuadratureRepresentationDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", QuadratureRepresentationDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2 ### the geometry studied is a square\n",
    "mesh_size_lst  = [        ] ### in mm\n",
    "mesh_size_lst += [0.1     ] # 0.10\n",
    "mesh_size_lst += [0.1/2**1] # 0.05\n",
    "\n",
    "cube_params = {\"X0\":0.2, \"Y0\":0.2, \"X1\":0.8, \"Y1\":0.8, \"l\":0.1} # cube of characteristic length 0.6 mm, default element size 0.1 mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deformation_type_lst  = [       ]\n",
    "deformation_type_lst += [\"grav\" ] ### body forces\n",
    "deformation_type_lst += [\"compx\"] ### boundary forces\n",
    "\n",
    "load_params_boundary = {\"type\":\"pres\", \"f\":0.3} ### boundary force, pressure = 0.3 kPa\n",
    "load_params_body = {\"type\":\"volu\", \"f\":0.3} ### body force = 0.3 mN/mm3\n",
    "\n",
    "const_params = {\"type\":\"blox\"} ### defining load and boundary conditions: here, the square is clamped on the left x boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_params = {\"model\":\"CGNH\", \"parameters\":{\"E\":1., \"nu\":0.3}} ### defining material constants for estimation, E is the Young's modulus in kPa, nu is the Poisson ratio [-]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = \"generate_images\"\n",
    "n_voxels = 100 ### number of voxels on the created images\n",
    "\n",
    "noise_level_lst  = [   ] ### investigated noise levels\n",
    "noise_level_lst += [0.3]\n",
    "noise_level_lst += [0.2]\n",
    "noise_level_lst += [0.1]\n",
    "noise_level_lst += [0.0]\n",
    "\n",
    "n_runs_for_noisy_images = 10 ### number of images generated for a given noise levels; for a same noise level, and for convergence of the estimation, different images are created since the noise added to the images is a random Gaussian field\n",
    "\n",
    "regul_level_lst  = [        ] ### regularization levels\n",
    "regul_level_lst += [0.1*2**3] # 0.8\n",
    "regul_level_lst += [0.1*2**1] # 0.2\n",
    "regul_level_lst += [0.      ] # 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying parameters for the estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### different cases investigated\n",
    "noise_from_images_lst = [True, False] ### synthetic measure generated by adding noise to images (True) or to displacements (False)\n",
    "refine_mesh = [True, False] ### refining the mesh or not\n",
    "load_type = [\"body_force\", \"boundary_force\"] ### either boundary force or body force\n",
    "fine_mesh_size = min(mesh_size_lst) ### getting the value for the finer mesh: for this value, the mesh will not be refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deformation_type in deformation_type_lst:\n",
    "    generate_images_and_meshes_from_RivlinCube( ### creating very fine mesh for image creation\n",
    "        images_n_dim = dim,\n",
    "        images_n_voxels = n_voxels,\n",
    "        deformation_type = deformation_type,\n",
    "        texture_type = \"no\",\n",
    "        noise_level = 0,\n",
    "        run_model = 1,\n",
    "        generate_images = 0)\n",
    "    for noise_level in noise_level_lst :\n",
    "        n_runs = n_runs_for_noisy_images if (noise_level > 0) else 1\n",
    "        for k_run in range(1, n_runs+1):\n",
    "            generate_images_and_meshes_from_RivlinCube(### creating images\n",
    "                images_n_dim = dim,\n",
    "                images_n_voxels = n_voxels,\n",
    "                deformation_type = deformation_type,\n",
    "                texture_type = \"tagging\",\n",
    "                noise_level = noise_level,\n",
    "                k_run = k_run if (n_runs > 1) else None,\n",
    "                run_model = 0,\n",
    "                generate_images = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground-truth motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deformation_type in deformation_type_lst:\n",
    "    for mesh_size in mesh_size_lst:\n",
    "        generate_images_and_meshes_from_RivlinCube(### ground-truth motion + meshes\n",
    "            images_n_dim = dim,\n",
    "            # images_n_voxels = 1,\n",
    "            mesh_size = mesh_size,\n",
    "            deformation_type = deformation_type,\n",
    "            texture_type = \"no\",\n",
    "            noise_level = 0,\n",
    "            run_model = 1,\n",
    "            generate_images = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for deformation_type in deformation_type_lst:\n",
    "    for noise_level in noise_level_lst:\n",
    "        n_runs = n_runs_for_noisy_images if (noise_level > 0) else 1 ### if no noise, there is no need for different samples; for noise levels higher than 0, a Gaussian noise id generated; there is hence the need for different samples, as randomness is introduced\n",
    "        for k_run in range(1, n_runs+1):\n",
    "            for mesh_size in mesh_size_lst:\n",
    "                for regul_level in regul_level_lst:\n",
    "                    ### getting regularization type, depending on the type of deformation applied\n",
    "                    if deformation_type == \"compx\":\n",
    "                        regul_type = \"discrete-equilibrated-tractions-tangential\"\n",
    "                        working_folder = \"run_warp_compx\"\n",
    "                        regul_b = 0.0\n",
    "                    else:\n",
    "                        regul_type = \"discrete-equilibrated-tractions-normal-tangential\"\n",
    "                        working_folder = \"run_warp_grav\"\n",
    "                        regul_b = 0.3\n",
    "\n",
    "                    #### getting files and folder names\n",
    "                    images_basename = \"square\"\n",
    "                    images_basename += \"-\"+deformation_type\n",
    "                    images_basename += \"-tagging\"\n",
    "                    images_basename += \"-noise=\"+str(noise_level)\n",
    "                    if (n_runs > 1):\n",
    "                        images_basename += \"-run=\"+str(k_run).zfill(2)\n",
    "                    mesh_basename = \"square\"\n",
    "                    mesh_basename += \"-\"+deformation_type\n",
    "                    mesh_basename += \"-h=\"+str(mesh_size)\n",
    "                    mesh_basename += \"-mesh\"\n",
    "                    if mesh_size != fine_mesh_size:\n",
    "                        meshes = [dolfin.Mesh(images_folder+\"/\"+mesh_basename+\"coarse.xml\"), dolfin.Mesh(images_folder+\"/\"+mesh_basename+\"refined.xml\")]\n",
    "                    else:\n",
    "                        meshes = [dolfin.Mesh(images_folder+\"/\"+mesh_basename+\"coarse.xml\")]\n",
    "                    if deformation_type == \"grav\":\n",
    "                        regul_surface_subdomain = []\n",
    "                        regul_surface_subdomain_id = []\n",
    "                        for mesh in meshes:\n",
    "                            regul_surface_subdomain_ = dolfin.MeshFunction(\"size_t\", mesh, mesh.topology().dim()-1)\n",
    "                            regul_surface_subdomain_.set_all(1)\n",
    "                            xmin_sd = dolfin.CompiledSubDomain(\"near(x[0], x0) && on_boundary\", x0 = 0.2)\n",
    "                            xmin_sd.mark(regul_surface_subdomain_, 0)\n",
    "                            regul_surface_subdomain.append(regul_surface_subdomain_)\n",
    "                            regul_surface_subdomain_id.append(1)\n",
    "                    else:\n",
    "                        regul_surface_subdomain = None\n",
    "                        regul_surface_subdomain_id = None\n",
    "                    working_basename = images_basename\n",
    "                    working_basename += \"-h=\"+str(mesh_size)\n",
    "                    working_basename += \"-\"+regul_type\n",
    "                    working_basename += \"-regul=\"+str(regul_level)\n",
    "                    working_basename += \"-b=\"+str(regul_b)\n",
    "\n",
    "                    #### tracking process\n",
    "                    if mesh_size != fine_mesh_size: ### get refined solution for multiresolution\n",
    "                        refinement_levels = [0,1]\n",
    "                    else:\n",
    "                        refinement_levels = [0]\n",
    "                    dwarp.warp_and_refine(\n",
    "                        working_folder = working_folder,\n",
    "                        working_basename = working_basename,\n",
    "                        images_folder = images_folder,\n",
    "                        images_basename = images_basename,\n",
    "                        meshes = meshes,\n",
    "                        regul_type = regul_type,\n",
    "                        regul_model = \"ciarletgeymonatneohookean\",\n",
    "                        regul_level = regul_level,\n",
    "                        regul_poisson = 0.3,\n",
    "                        regul_b = [regul_b]+[0.]*(dim-1),\n",
    "                        regul_surface_subdomain_data = regul_surface_subdomain,\n",
    "                        regul_surface_subdomain_id = regul_surface_subdomain_id,\n",
    "                        relax_type = \"backtracking\",\n",
    "                        tol_dU = 1e-2,\n",
    "                        n_iter_max = 100,\n",
    "                        normalize_energies = 1,\n",
    "                        refinement_levels = refinement_levels,\n",
    "                        silent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_lst = [] ### defining SNRs -- Signal-to-Noise ratios--\n",
    "for noise in noise_level_lst:\n",
    "    if noise == 0.:\n",
    "        SNR_lst.append(40.) ### setting the SNR arbitrarily when should be +∞\n",
    "    else:\n",
    "        SNR_lst.append(1/noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_results_to_pdf(results_all = [], SNR_lst = [], method_lst = [], mesh_size = 0.1, noise_from_images = False, load_type = \"body_force\", regul = \"\", refine = True): ### writing results to pdf\n",
    "    \n",
    "    ### plotting parameters\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.rc(\"xtick\", labelsize = 16)\n",
    "    plt.rc(\"ytick\", labelsize = 16)\n",
    "    plt.rc(\"legend\", fontsize = 12)\n",
    "    plt.ylim([-100, 100])\n",
    "    color_lst = ['forestgreen', 'royalblue', 'firebrick', 'gold'] #### colors associated to each method\n",
    "\n",
    "    ### labels\n",
    "    plt.xlabel(\"Signal to Noise Ratio (SNR)\", fontsize = 12)\n",
    "    plt.ylabel(\"Estimation error (%)\", fontsize = 12)\n",
    "    label_lst = [\"EGM\", \"VFM (plane wave as Virtual Field)\", \"VFM (Virtual Field from [Deng et al.])\", \"FEMU\"] ### labels for legends\n",
    "\n",
    "    for method in method_lst:\n",
    "        plt.plot(SNR_lst, results_all[str(method)][\"E_average\"], color = color_lst[0], label = label_lst[0])\n",
    "        plt.xlim([3.3, 20.])\n",
    "        ax.fill_between(SNR_lst, results_all[str(method)][\"E_+\"], results_all[str(method)][\"E_-\"], alpha = 0.5, color = color_lst[0])\n",
    "        plt.gca().set_xscale('log')\n",
    "        \n",
    "        color_lst = color_lst[1:]\n",
    "        label_lst = label_lst[1:]\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xticks([], minor = True)\n",
    "    plt.xticks(SNR_lst, [3.3, 5, 10, '$\\infty$'])\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(\"./plot_noise_error_different_methods-mesh_size = \"+str(mesh_size)+\"refine = \"+str(refine)+\"-noise_from_images = \"+str(noise_from_images)+\"-load_type = \"+str(load_type)+\"regul = \"+str(regul)+\".pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_noise_on_disp(method_lst = [], load_type = \"body_force\", load_params = {}, mesh_size = 0.1, cube_params = {}, refine = True, SNR_lst = [], regul_number = 0.3): ### synthetic data by adding noise to displacements\n",
    "    results_all = {}\n",
    "    for method in method_lst: ## for each method\n",
    "        results_std = {}\n",
    "        results = {}\n",
    "        noise_results = []\n",
    "        E_average, E_plus, E_minus = [], [], []\n",
    "        E_all = []\n",
    "        for noise in noise_level_lst: ### for each noise level\n",
    "            E_results = []\n",
    "            for i in range(1, 11): ### 10 iterations for each noise level, several iterations are required since we added Gaussian noise \n",
    "                noise_results.append(noise)\n",
    "                try:\n",
    "                    E = destim.identifying_parameter(method = method, delta = 9*0.6, load_type = load_type, load_params = load_params, mesh_size = mesh_size, cube_params = cube_params, refine = refine, noise_from_images = False, noise = noise, regul_number = regul_number)\n",
    "                    if \"refine\" in cube_params.keys() and not refine:\n",
    "                        cube_params.pop(\"refine\") \n",
    "                    E_error = (E-1)*100\n",
    "                    E_all.append(E_error)\n",
    "                    E_results.append(E_error)\n",
    "                except: ##### when adding highly unstructured noise, the computation may not always converge; in this case the results are not taken into account\n",
    "                    pass\n",
    "            E_average.append(numpy.average(E_results))\n",
    "            E_plus.append(numpy.average(E_results) + numpy.std(E_results))\n",
    "            E_minus.append(numpy.average(E_results) - numpy.std(E_results))\n",
    "        results_std[\"noise\"] = noise_level_lst\n",
    "        results_std[\"E_+\"] = E_plus\n",
    "        results_std[\"E_-\"] = E_minus\n",
    "        results_std[\"E_average\"] = E_average\n",
    "        results[\"noise\"] = noise_results\n",
    "        results[\"E\"] = E_all\n",
    "        results_all[str(method)] = results_std\n",
    "    writing_results_to_pdf(mesh_size = mesh_size, SNR_lst = SNR_lst, results_all = results_all, noise_from_images = False, load_type = load_type, method_lst = method_lst, refine = refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_noise_on_images(method_lst = [], load_type = \"body_force\", load_params = {}, mesh_size = 0.1, cube_params = {}, refine = True, SNR_lst = [], regul_number = 0.3): ### synthetic data by adding noise to images\n",
    "    results_all = {}\n",
    "    for regul in regul_level_lst: ### for each regularization level\n",
    "        for method in method_lst: ### for each method\n",
    "            results_std = {}\n",
    "            results = {}\n",
    "            noise_results = []\n",
    "            E_average, E_plus, E_minus = [], [], []\n",
    "            E_all = []\n",
    "            for noise in noise_level_lst: ### for each noise level\n",
    "                E_results = []\n",
    "                for i in range(1, 11): ### 10 iterations for each noise level, several iterations are required since we added Gaussian noise --10 corresponding to the number of images generated for each noise level, for each regularization number--\n",
    "                    run = str(i).zfill(2)\n",
    "                    noise_results.append(noise)\n",
    "                    try:\n",
    "                        E = destim.identifying_parameter(method = method, delta = 9*0.6, load_type = load_type, load_params = load_params, mesh_size = mesh_size, cube_params = cube_params, refine = refine, noise_from_images = True, noise = noise, regul = regul, run = run, regul_number = regul_number)\n",
    "                        E_error = (E-1)*100\n",
    "                        E_all.append(E_error)\n",
    "                        E_results.append(E_error)\n",
    "                        print(\"E estimated\", E)\n",
    "                    except: ### in case the computation does not converge\n",
    "                        pass\n",
    "                E_average.append(numpy.average(E_results))\n",
    "                E_plus.append(numpy.average(E_results)+numpy.std(E_results))\n",
    "                E_minus.append(numpy.average(E_results)-numpy.std(E_results))\n",
    "                results_std[\"noise\"] = noise_level_lst\n",
    "            results_std[\"E_+\"] = E_plus\n",
    "            results_std[\"E_-\"] = E_minus\n",
    "            results_std[\"E_average\"] = E_average\n",
    "            results[\"noise\"] = noise_results\n",
    "            results[\"E\"] = E_all\n",
    "            results_all[str(method)] = results_std\n",
    "        writing_results_to_pdf(mesh_size = mesh_size, SNR_lst = SNR_lst, results_all = results_all, noise_from_images = True, load_type = load_type, method_lst = method_lst, regul = regul, refine = refine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_lst = [\"EGM\", \"VFM\", \"VFM_deng\", \"FEMU\"] ### 4 different estimation methods investigated \n",
    "\n",
    "results_all = {}\n",
    "\n",
    "for mesh_size in mesh_size_lst:\n",
    "    for refine in refine_mesh:\n",
    "        print('refine', refine)\n",
    "        if refine and mesh_size == fine_mesh_size: ### meshes with elements smaller than 0.05 --in this example-- were not investigated in the scope of this article\n",
    "            pass\n",
    "        else:\n",
    "            for load in load_type:\n",
    "                print(\"load\", load)\n",
    "                assert (load in (\"body_force\", \"boundary_force\" )), \"Load should be body_force or boundary_force, aborting...\"\n",
    "                if load == \"body_force\":\n",
    "                    load_params = load_params_body\n",
    "                    regul_number = 0.3    ### sets volume regularization, chosen at the ground-truth value --0.3 mN--\n",
    "                if load == \"boundary_force\":\n",
    "                    load_params = load_params_boundary\n",
    "                    regul_number = 0.0                    \n",
    "                for noise_from_images in noise_from_images_lst:\n",
    "                    print(\"noise_from_images\", noise_from_images)\n",
    "                    if noise_from_images:\n",
    "                        run_noise_on_images(method_lst = method_lst, load_type = load, load_params = load_params, mesh_size = mesh_size, cube_params = cube_params, refine = refine, SNR_lst = SNR_lst, regul_number = regul_number)\n",
    "                    else:\n",
    "                        run_noise_on_disp(method_lst = method_lst, load_type = load, load_params = load_params, mesh_size = mesh_size, cube_params = cube_params, refine = refine, SNR_lst = SNR_lst, regul_number = regul_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
